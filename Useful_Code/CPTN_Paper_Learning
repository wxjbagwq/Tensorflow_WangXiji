###
# Detecting Text in Natural Image with Connectionist Text Proposal Network (CTPN)
###

# 0.Abstract
# (1) 用一种竖直anchor机制去预测text/non-text
# (2) 结构:CNN -> Proposal -> RNN
# (3) CTPN可以在多语言多尺寸的文本检测中工作，并且采用自底向上的方法

# 1.Introduction
# (1) 两个核心子任务:文本检测和文本识别
# (2) 在文本精确定位中的挑战主要是:各式各样的文字形式以及非常杂乱的背景干扰
# (3) CTPN是Faster_R_CNN针对于文本检测中的一种发展，因为文本检测需要更加的精细，把文本区域都包含进去
# (4) 端到端的模型

# 1.1 Contributions
# (1) CTPN可以在卷积层中定位文本
# (2) *** 文章在图1中提出了CTPN的架构, 具体见笔记本 ***
# (3) CTPN把文本检测用一堆小的竖直的框来完成
# (4) CTPN使用了BLSTM(双向LSTM)，在检测的过程中可以探索文本的上下文信息以提高检测水平

# 2.Related Work
# 2.1 Text Detction
# (1) 常见的基于字体或笔画的文本检测中使用的方法包括:CCs以及Sliding-window(滑动窗口)办法
# (2) CCs通过区分文本和非文本像素的低级特征如强度，颜色，梯度等来实现，很粗略
# (3) 滑动窗口的办法非常复杂因为窗口很多，大量重复计算，而且准确率不咋样
# 2.2 Object detection
# (1) CNN通过对低级特征的提取和强大的分类器来实现了物体的检测
# (2) Selective_Search(选择性搜索)是现在目标检测中应用广泛的办法，主要是R-CNN及其扩展
# (3) 最关键的是文本检测有它的特殊性，很难直接用Faster-R-CNN这种模型直接用在文本检测中去

# 3.Connectionist Text Proposal Network
# (1) 三个办法实现: 使用fine_scale(精细检测的，通俗说就是很细很瘦高的)的proposal
#                  Recurrent_connectionist文本proposal(也就是后面连接了一个双向LSTM)
#                  side-refinement侧面改进
# 3.1 Dectecting Text in Fine-scale Proposal
# (1) CTPN使用的是16像素宽的精细文本proposal
# (2) *** 在feature_map(VGG16的conv5)中使用3*3的滑动窗口 ***
# (3) *** total_stride = 16, 感受野 = 228 ***
# (4) RPN直接用于文本检测的话容易出现问题，不能有好的检测效果,因为单词或者文字各个都是独立的，容易混淆他们的位置
# (5) 通过固定较难预测的水平位置来预测proposal的竖直位置
# (6) CTPN使用竖直的anchor来预测每个fine_scale_proposal的text/non-text分数和y轴位置
# (7) 精细文本proposal(fine-scale-text-proposal)设计
# (7.1) detector密集扫描整个feature_map
# (7.2) text_proposal在输入图像中具有16个像素的宽度，等效于feature_map里面的每个像素点的感受野宽度为16
# (7.3) *** 然后设计K个竖直的具有相同水平位置(?)的16个像素宽度的垂直位置的高度可变的anchor来为每个proposal预测y坐标 ***
# (7.4) 文章的实验中使用的是10个anchor，高度从11到273个像素点(每次除以0.7)
# (7.5) *** 垂直坐标(vertical coordinates)是通过proposal_bounding_box的高度和y轴中心来测量的 ***
# (7.6) 计算anchor的bounding_box的预测的相对垂直坐标(v)的公式见笔记本！
# (7.7) 每个text_proposal在输入图像中都有大小为h*16的bounding_box
# (7.8) 文章中说一般text_proposal的感受野尺寸都会大大小于228*228
# (8) 检测处理(detction processing)设计
# (8.1) CONV使用的是VGG16模型,所以得到的feature_map尺寸为: W*H*C(conv5)(C:通道数量,W*H:特征图的尺寸)
# (8.2) detector使用3*3*C的窗口密集滑动过(应该理解成步长等于1)feature_map用来产生预测
# (8.3) *** 对于每个预测，水平位置和K个anchor的位置是固定的，可以把feature_map里面的窗口位置映射到输入图像来预先计算 ***
# (8.4) 在每个窗口输出K个anchor的text/non-text的scores和y坐标
# (8.5) 非极大值抑制使用的是text/non-text的score>0.7
# 3.2 Recurrent Connectionist Text Proposal
# (1) 由于文本有很强烈的上下文顺序特征，所以单独的处理proposal是不行的，所以要对每一个proposal进行相关的处理 --> 这是使用双向LSTM的原因！
# (2) *** CTPN在conv5上面增加了一个RNN，把每个窗口的卷积feature作为输入，并且在隐藏层Ht中循环更新其内部状态 *** --> 这部分的公式和解释见笔记本！！
# (3) *** 剩下的整个RNN层的设计相关见笔记本！！！ ***
# 3.3 Side-refinement
# (1) 文本行构建：
# (1.1) 给proposal Bi一个配对的邻居Bj定义为: Bj->Bi如果满足(1.2),(1.3),(1.4)的三个条件
# (1.2) Bj是Bi水平最近的
# (1.3) Bj和Bi的水平距离小于50个像素
# (1.4) 他们的垂直重叠值大于0.7
# (1.5) 如果两个proposal有Bj->Bi,并且Bi->Bj的话，就把这两个proposal分成一对(a pair)
# (1.6) 整个文本行就是由这一些连续的连接的pairs构成的
# (2) Side-refinement处理
# (2.1)





















