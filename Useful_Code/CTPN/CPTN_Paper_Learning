###
# Detecting Text in Natural Image with Connectionist Text Proposal Network (CTPN)
###

# 0.Abstract
# (1) 用一种竖直anchor机制去预测text/non-text
# (2) 结构:CNN -> Proposal -> RNN
# (3) CTPN可以在多语言多尺寸的文本检测中工作，并且采用自底向上的方法

# 1.Introduction
# (1) 两个核心子任务:文本检测和文本识别
# (2) 在文本精确定位中的挑战主要是:各式各样的文字形式以及非常杂乱的背景干扰
# (3) CTPN是Faster_R_CNN针对于文本检测中的一种发展，因为文本检测需要更加的精细，把文本区域都包含进去
# (4) 端到端的模型

# 1.1 Contributions
# (1) CTPN可以在卷积层中定位文本
# (2) *** 文章在图1中提出了CTPN的架构, 具体见笔记本 ***
# (3) CTPN把文本检测用一堆小的竖直的框来完成
# (4) CTPN使用了BLSTM(双向LSTM)，在检测的过程中可以探索文本的上下文信息以提高检测水平


# 2.Related Work
# 2.1 Text Detction
# (1) 常见的基于字体或笔画的文本检测中使用的方法包括:CCs以及Sliding-window(滑动窗口)办法
# (2) CCs通过区分文本和非文本像素的低级特征如强度，颜色，梯度等来实现，很粗略
# (3) 滑动窗口的办法非常复杂因为窗口很多，大量重复计算，而且准确率不咋样
# 2.2 Object detection
# (1) CNN通过对低级特征的提取和强大的分类器来实现了物体的检测
# (2) Selective_Search(选择性搜索)是现在目标检测中应用广泛的办法，主要是R-CNN及其扩展
# (3) 最关键的是文本检测有它的特殊性，很难直接用Faster-R-CNN这种模型直接用在文本检测中去


# 3.Connectionist Text Proposal Network
# (1) 三个办法实现: 使用fine_scale(精细检测的，通俗说就是很细很瘦高的)的proposal
#                  Recurrent_connectionist文本proposal(也就是后面连接了一个双向LSTM)
#                  side-refinement侧面改进

# 3.1 Dectecting Text in Fine-scale Proposal
# (1) CTPN使用的是16像素宽的精细文本proposal
# (2) *** 在feature_map(VGG16的conv5)中使用3*3的滑动窗口 ***
# (3) *** total_stride = 16, 感受野 = 228 ***
# (4) RPN直接用于文本检测的话容易出现问题，不能有好的检测效果,因为单词或者文字各个都是独立的，容易混淆他们的位置
# (5) 通过固定较难预测的水平位置来预测proposal的竖直位置
# (6) CTPN使用竖直的anchor来预测每个fine_scale_proposal的text/non-text分数和y轴位置
# (7) 精细文本proposal(fine-scale-text-proposal)设计
# (7.1) detector密集扫描整个feature_map
# (7.2) text_proposal在输入图像中具有16个像素的宽度，等效于feature_map里面的每个像素点的感受野宽度为16
# (7.3) *** 然后设计K个竖直的具有相同水平位置(?)的16个像素宽度的垂直位置的高度可变的anchor来为每个proposal预测y坐标 ***
# (7.4) 文章的实验中使用的是10个anchor，高度从11到273个像素点(每次除以0.7)
# (7.5) *** 垂直坐标(vertical coordinates)是通过proposal_bounding_box的高度和y轴中心来测量的 ***
# (7.6) 计算anchor的bounding_box的预测的相对垂直坐标(v)的公式见笔记本！
# (7.7) 每个text_proposal在输入图像中都有大小为h*16的bounding_box
# (7.8) 文章中说一般text_proposal的感受野尺寸都会大大小于228*228
# (8) 检测处理(detction processing)设计
# (8.1) CONV使用的是VGG16模型,所以得到的feature_map尺寸为: W*H*C(conv5)(C:通道数量,W*H:特征图的尺寸)
# (8.2) detector使用3*3*C的窗口密集滑动过(应该理解成步长等于1)feature_map用来产生预测
# (8.3) *** 对于每个预测，水平位置和K个anchor的位置是固定的，可以把feature_map里面的窗口位置映射到输入图像来预先计算 ***
# (8.4) 在每个窗口输出K个anchor的text/non-text的scores和y坐标
# (8.5) 非极大值抑制使用的是text/non-text的score>0.7

# 3.2 Recurrent Connectionist Text Proposal
# (1) 由于文本有很强烈的上下文顺序特征，所以单独的处理proposal是不行的，所以要对每一个proposal进行相关的处理 --> 这是使用双向LSTM的原因！
# (2) *** CTPN在conv5上面增加了一个RNN，把每个窗口的卷积feature作为输入，并且在隐藏层Ht中循环更新其内部状态 *** --> 这部分的公式和解释见笔记本！！
# (3) *** 剩下的整个RNN层的设计相关见笔记本！！！ ***

# 3.3 Side-refinement
# (1) 文本行构建：
# (1.1) 给proposal Bi一个配对的邻居Bj定义为: Bj->Bi如果满足(1.2),(1.3),(1.4)的三个条件
# (1.2) Bj是Bi水平最近的
# (1.3) Bj和Bi的水平距离小于50个像素
# (1.4) 他们的垂直重叠值大于0.7
# (1.5) 如果两个proposal有Bj->Bi,并且Bi->Bj的话，就把这两个proposal分成一对(a pair)
# (1.6) 整个文本行就是由这一些连续的连接的pairs构成的
# (2) Side-refinement处理
# (2.1) 在文本检测中，如果两个水平边的proposal没有检测出来会导致很严重的问题, Side-refinement就是为了精确处理这个问题的办法
# (2.2) *** Side-refinement的具体处理办法见笔记本！！！ ***

# 3.4 Model Outputs and Loss Function
# (1) 如图1所示，在最后一个FC层连接了三个output，分别是: 2K个vertical_coordinates(竖直坐标); 2K个scores; K个side-refinement(边界精细偏移量)
# (2) 使用多任务学习来联合优化模型参数
# (3) *** 损失函数见笔记本！！！ ***

# 3.5 Training and Implementation Details(训练和实施细节)
# (1) 使用标准的反向传播和随机梯度下降(stochastic gradient descent,SGD)来进行End2End的训练
# (2) CTPN与RPN类似，训练样本是anchor,其位置可以在img中预先计算，以便找到相应的GT的label
# (3) 训练标签(training label)
# (3.1) 在text/non-text的分类中，把二元标签分配给正(text)anchor和负(non-text)anchor
# (3.2) 正anchor要满足下面的(3.3)和(3.4)
# (3.3) 和GT要有大于0.7的IoU
# (3.4) 和GT有最高的IoU
# (3.5) 由(3.4)可以知道即使是一个非常小的文本图像也会分配一个正anchor
# (3.6) 负anchor被定义成:和GT的IoU小于0.5
# (4) 训练数据(training data)
# (4.1) 在训练过程中，mini-batch里面的每个samples都是从一张图片里面收集的
# (4.2) mini-batch中的anchor的数量: Ns=128,正负样本比例为1:1
# (4.3) 如果正样本的数目少于64，则会用负样本填充到mini-batch中去
# (4.4) *** 文章里面把图像的短边都搞成600的同时保持高宽比 ***
# (5) 实施细节(Implementation detail)
# (5.1) 文中的VGG16是在ImageNet数据上预先训练好的(这个是惯例)
# (5.2) RNN层和Output_layer用的是(均值为0，标准差为0.01)的高斯分布随机权重初始化
# (5.3) momentum=0.9
# (5.4) 0.0005权重衰减
# (5.5) 在第一次的16K次迭代中学习率等于0.001，随后再以0.0001的学习率进行4K次迭代

# 4.Experimental Results and Discussions
# (1) 文章中的实验是先单独验证每个组件的效率，比如fine-scale_text_proposal_detection和RNN

# 4.1 Benchmarks and Evaluation Metric(基准和评估指标)
# (1) 原文:The Multilingual scene text dataset is collected by [24].
# (1) 翻译:  多语言场景文本数据集由[24]收集

# 4.2 Fine-Scale Text Proposal Network with Faster R-CNN
# (1) fine-scale_text_proposal针对文本识别提升了准确率

# 4.3 Recurrent Connectionist Text Proposals
# (1) RNN在模糊的文本中检测效果显著

# 4.4 Comparisons with state-of-the-art results(与最先进的结果进行比较)

